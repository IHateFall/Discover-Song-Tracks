{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SONG TRACKS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS) #LDA\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(car)\n",
    "library(ca) #correspondence analysis\n",
    "library(psych) \n",
    "library(caret) #cofusion martrix\n",
    "library(cluster)    # clustering algorithms\n",
    "library(factoextra) # clustering algorithms & visualization\n",
    "library(purrr)\n",
    "library(gridExtra) #visualize number of k clusters\n",
    "library(class)\n",
    "library(REdaS)\n",
    "source(\"Confusion.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unable to load all the packages in R jupyter notebook environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile1=read.csv('song_data.csv')\n",
    "head(infile1)\n",
    "bart_spher(infile1[2:15])\n",
    "infile2=read.csv('song_info.csv')\n",
    "head(infile2)\n",
    "infile1$duration=round(infile1$song_duration_ms*1.66667e-5,3) #converting to minutes\n",
    "infile1$artist=infile2$artist_name\n",
    "nrow(infile1)\n",
    "#remove duplicates\n",
    "clean_infile1=distinct(infile1)\n",
    "nrow(clean_infile1)\n",
    "clean_infile1=subset(clean_infile1,select=-c(song_duration_ms))\n",
    "#DISCRITIZE AUDIO VALENCE\n",
    "summary(clean_infile1$audio_valence)\n",
    "clean_infile1$valence[clean_infile1$audio_valence<=0.332]='Low'\n",
    "clean_infile1$valence[clean_infile1$audio_valence<=0.7278 & clean_infile1$audio_valence>0.332]='Medium'\n",
    "clean_infile1$valence[clean_infile1$audio_valence>0.7278]='High'\n",
    "\n",
    "summary(clean_infile1$song_popularity)\n",
    "clean_infile1$pop[clean_infile1$song_popularity>=63.75]='Very Popular'\n",
    "clean_infile1$pop[clean_infile1$song_popularity<=37]='Very Not Popular'\n",
    "clean_infile1$pop[clean_infile1$song_popularity>37 & clean_infile1$song_popularity<=52]='Not Popular'\n",
    "clean_infile1$pop[clean_infile1$song_popularity>52 & clean_infile1$song_popularity<63.75]='Popular'\n",
    "boxplot(clean_infile1$song_popularity~clean_infile1$valence,\n",
    "        xlab='Valence',ylab='Popularity')\n",
    "clean_infile1$pop=as.factor(clean_infile1$pop)\n",
    "clean_infile1$valence=as.factor(clean_infile1$valence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_size <- floor(0.70 * nrow(clean_infile1))\n",
    "set.seed(463)\n",
    "train_ind <- sample(seq_len(nrow(clean_infile1)), size = smp_size)\n",
    "train <- clean_infile1[train_ind, ]\n",
    "test <- clean_infile1[-train_ind, ]\n",
    "head(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRESPONDENCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catable=table(clean_infile1$valence, clean_infile1$pop)\n",
    "catable\n",
    "margin.table(catable, 1) \n",
    "margin.table(catable, 2) \n",
    "round(prop.table(catable),4) # cell percentages\n",
    "round(prop.table(catable, 1),4) # row percentages \n",
    "round(prop.table(catable, 2),4) # column percentages\n",
    "#correspondance fit\n",
    "fitca <- ca(catable)\n",
    "mosaicplot(catable,shade=TRUE,main='Popularity vs. Valence')\n",
    "print(fitca) # basic results \n",
    "summary(fitca) \n",
    "plot(fitca) # symmetric map\n",
    "plot(fitca, mass = TRUE, contrib = \"absolute\", map =\n",
    "       \"rowgreen\", arrows = c(FALSE, TRUE)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR DISCRIMINANT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatrain1=subset(train,select=-c(artist,duration,song_popularity,song_name,audio_mode,pop,audio_valence))\n",
    "ldatest=subset(test,select=-c(artist,duration,song_popularity,song_name,audio_mode,pop,audio_valence))\n",
    "vlda = lda(valence ~ ., data=ldatrain1)\n",
    "vlda\n",
    "\n",
    "#vlda$scaling #the loadings: how each variable contributes to the LD\n",
    "#plot(vlda)\n",
    "#reorder the loadings helps to interpret the results\n",
    "print(vlda$scaling[order(vlda$scaling[,1]),])\n",
    "#predict trianing values \n",
    "#use the scores to discriminate the classes\n",
    "vlda.values = predict(vlda) #predict test set values\n",
    "head(vlda.values$x)\n",
    "head(ldatrain1)\n",
    "compare=subset(ldatrain1,select=-c(valence))\n",
    "compare$LD=vlda.values$x\n",
    "head(compare)\n",
    "round(cor(compare),2)\n",
    "\n",
    "par(mar=c(4,4,4,4))\n",
    "ldahist(data=vlda.values$x[, 1], g=ldatrain1$valence)\n",
    "ldahist(data=vlda.values$x[, 2], g=ldatrain1$valence)\n",
    "plot(vlda.values$x[, 1], vlda.values$x[, 2], col=ldatrain1$valence, pch=16)\n",
    "ldatable=table(ldatrain1$valence, vlda.values$class)\n",
    "confusion(vlda.values$class, ldatrain1$valence)\n",
    "confusionMatrix(ldatable)\n",
    "\n",
    "#test model performance on test set \n",
    "test.lda.values1 = predict(vlda,newdata =ldatest) #predict test set values\n",
    "test.lda.values1$x\n",
    "ldahist(data=test.lda.values1$x[, 1], g=test$valence)\n",
    "ldahist(data=test.lda.values1$x[, 2], g=test$valence)\n",
    "plot(test.lda.values1$x[, 1], test.lda.values1$x[, 2], col=test$valence, pch=16)\n",
    "ldatab=table(test$valence, test.lda.values1$class)\n",
    "confusionMatrix(ldatab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring \"very popylar songs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting subset\n",
    "popsong=filter(clean_infile1,song_popularity>80) #examine songs have over 80 pop score\n",
    "popsong=popsong[order(-popsong$song_popularity),]\n",
    "nrow(distinct(popsong))\n",
    "popsong=popsong %>% distinct(song_name,.keep_all=T)\n",
    "nrow(popsong)\n",
    "singers=popsong$artist\n",
    "row.names(popsong)=popsong$song_name\n",
    "head(popsong)\n",
    "#for (i in singers)\n",
    "#{x=length(which(clean_infile1$artist==i))\n",
    "#cat(i,x,sep=':',fill=T)}\n",
    "popsong$count=c(10,44,11,2,16,45,9,12,1,8,25,6,5,6,6,6,10,25,18,7,10,4,5,16,3,20,6,1,45,\n",
    "                10,10,4,45,16,16,16,9,10,15,6,22,17,8,16,6,7,7,17,6,4,25,7,6,13,14,25,9,\n",
    "                5,12,13,14,11,6,4,5,6,3,4,25,9,7,8,4,2,17,8,10,10,1,17,1,13,10,25,17,2,14,\n",
    "                6,2,1,25,4,3,23,22,8,7,1,7,1,12,17,3,25,10,11,3,17,7,7,7,14,5,6,6,4,10,1,10,\n",
    "                4,5,17,57,6,3,10,25,1,22,7,22,17,11,8,4,5,7,4,3,25,10,17,9,9,1,5,7,23,9,18,\n",
    "                9,8,1,9,13,7,10,6,9,12,16,11,14,11,10,18,23,23,10,6,2,7,45,10,13,16,18,1,57,9,\n",
    "                13,6,10,3,6,7,25,2,1,6,13,22,5,1,1,11,14,6,11,5,4,8,11,16,17,16,10,8,10,6,4,2,\n",
    "                3,44,13,7,10,1,1,1,2,1,6,10,9,6,10,8,15,10,3,7,8,11,12,6,10,10,9,5,23,2,2,1,1,11,\n",
    "                4,4,7,2,4,9,7,4,9,22,7,5,10,22,10,22,10,4,6,4,6,6,2,8,3,11,5,10,1,2,5,6,17,4,7,10,\n",
    "                9,2,17,4,1,7,16,17,4,23,7,7,5,7,2,5,7,16,18,12,18,5,7,9,5,7,2,2,8,7,11,6,6,57,1,12,\n",
    "                8,1,13,3,19,4,10,18,10,18,7,4,5,23,5,7,11,11,5,6,17,2,3,23,9,13,12,3,4,11,10,9,3,4,\n",
    "                10,2,10,6,7,5,13,9,25,4,9,8,15,3,9,3,8,2,7,25,4,16,8,13,13,6,3,4,16,18,3,1,6,5,16,\n",
    "                8,44,13,5,5,14,4,1,12,6,15,22,10,9,7,3,6,8,8,12,6,5,10,15,6,17,10,5,11,14,9,2,1,10,\n",
    "                3,11,1)\n",
    "cor(popsong$song_popularity,popsong$count)\n",
    "summary(popsong) #will remove some variables because of commonalities\n",
    "summary(popsong$count)\n",
    "popsong=subset(popsong,select=-c(song_name,instrumentalness,liveness,audio_mode,time_signature,duration,pop))\n",
    "head(popsong)\n",
    "cor(popsong$song_popularity,popsong$audio_valence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTI-DIMENSIONAL SCALING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits=subset(popsong,select=-c(artist,valence,pop,song_popularity))\n",
    "head(hits)\n",
    "hits.dist <- dist(hits)\n",
    "summary(hits.dist)\n",
    "hits.mds <- isoMDS(hits.dist)\n",
    "plot(hits.mds$points, type = \"n\")\n",
    "text(hits.mds$points, labels = as.character(1:nrow(hits)))\n",
    "hits.sh <- Shepard(hits.dist,hits.mds$points)\n",
    "plot(hits.sh, pch = \".\")\n",
    "lines(hits.sh$x,hits.sh$yf, type = \"S\",col='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRICIPAL COMPONENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph1=prcomp(hits[1:7],scale=T) #fit on all metric data\n",
    "summary(ph1) #how much variance of the ds is explained; and cumulative proportion\n",
    "plot(ph1) #knee plot to see how many pcs needed to explain at least 90%; agree with above?\n",
    "abline(1,0,col='red')\n",
    "#round(p1$rotation,2) #formula of each pc;% of each variable in each pc;components of each pc\n",
    "pch1= principal(hits[1:7], rotate=\"varimax\", nfactors=4, scores=TRUE)\n",
    "print(pch1$loadings, cutoff=.4, sort=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMON FACTOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fith=factanal(hits[1:7],3, rotation=\"varimax\")\n",
    "print(fith, digits=2, cutoff=.4, sort=TRUE)\n",
    "# plot factor 1 by factor 2 \n",
    "loadh=fith$loadings[,1:2] \n",
    "plot(loadh,type=\"n\") # set up plot \n",
    "text(loadh,labels=names(hits),cex=.7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DENSITY CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNNdistplot(hits, k = 5)\n",
    "abline(h=.5, col = \"red\", lty=2)\n",
    "dens = dbscan(hits, eps=.5,MinPts = 10)\n",
    "dens\n",
    "pairs(hits, col = dens$cluster + 1L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
